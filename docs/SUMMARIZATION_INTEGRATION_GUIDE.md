# –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –≤ RAG-–ø–∞–π–ø–ª–∞–π–Ω

## üéØ –ß—Ç–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ

### –ù–æ–≤—ã–π –º–æ–¥—É–ª—å
üìÅ `backend/services/summarization.py` - —Å–µ—Ä–≤–∏—Å —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏

**–û—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏:**
- `summarize_text()` - –ø—Ä–æ—Å—Ç–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è
- `summarize_long_text()` - map-reduce –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤
- `summarize_chunks()` - —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è search results
- `summarize_document_by_id()` - —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è —Ü–µ–ª–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞

---

## üöÄ –í–∞—Ä–∏–∞–Ω—Ç—ã –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏

### –í–∞—Ä–∏–∞–Ω—Ç 1: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è (5 –º–∏–Ω—É—Ç)

**–î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–π endpoint –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏:**

```python
# –í backend/app.py –¥–æ–±–∞–≤–∏—Ç—å:

from services.summarization import summarize_document_by_id
from pydantic import BaseModel

class SummarizeRequest(BaseModel):
    doc_id: str
    space_id: str
    focus: Optional[str] = None

@app.post("/summarize")
def summarize_document(req: SummarizeRequest = Body(...)):
    """–°—É–º–º–∞—Ä–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç –ø–æ ID"""
    summary = summarize_document_by_id(
        doc_id=req.doc_id,
        space_id=req.space_id,
        focus=req.focus
    )
    return {"doc_id": req.doc_id, "summary": summary}
```

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
```bash
curl -X POST http://localhost:8000/summarize \
  -H "Content-Type: application/json" \
  -d '{
    "doc_id": "migration_plan_xyz",
    "space_id": "company_acme",
    "focus": "budget and timeline"
  }'
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**
```json
{
  "doc_id": "migration_plan_xyz",
  "summary": "Migration plan overview: Budget $200K, Timeline 6 months (Jan-Jun 2025), Using Kubernetes on AWS, Team of 5 engineers, Main risk: data migration complexity"
}
```

---

### –í–∞—Ä–∏–∞–Ω—Ç 2: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –≤ RAG (15 –º–∏–Ω—É—Ç)

**–ö–æ–≥–¥–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å—É–º–º–∞—Ä–∏–∑–∏—Ä–æ–≤–∞—Ç—å:**

```python
# –í backend/app.py, –≤ —Ñ—É–Ω–∫—Ü–∏–∏ ask():

from services.summarization import summarize_chunks

@app.post("/ask")
def ask(req: AskRequest = Body(...)):
    # ... existing search logic ...
    fused = _limit_one_chunk_per_doc(candidate_pool, effective_top_k)
    
    # NEW: Check if context is too large
    context_tokens = _count_context_tokens(fused)
    max_context = 4000  # Conservative limit
    
    if context_tokens > max_context:
        # Summarize chunks before RAG
        print(f"[RAG] Context too large ({context_tokens} tokens). Summarizing...")
        
        summary = summarize_chunks(fused, query=req.q, max_output_tokens=2000)
        
        # Use summary instead of raw chunks
        prompt = (
            "–¢—ã ‚Äî –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –æ—Ç–≤–µ—á–∞–π —Å—Ç—Ä–æ–≥–æ –ø–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–º—É –ö–û–ù–¢–ï–ö–°–¢–£. "
            "–ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ ‚Äî —Ç–∞–∫ –∏ —Å–∫–∞–∂–∏.\n\n"
            f"–ö–û–ù–¢–ï–ö–°–¢ (summarized from {len(fused)} chunks):\n{summary}\n\n"
            f"–í–û–ü–†–û–°:\n{req.q}\n\n"
            "–û—Ç–≤–µ—Ç—å –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É."
        )
    else:
        # Normal RAG
        prompt = build_prompt(fused, req.q)
    
    answer = call_llm(prompt)
    # ... rest of the logic ...
```

**–≠—Ñ—Ñ–µ–∫—Ç:**
- ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –±–æ–ª—å—à–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã
- ‚úÖ –ü—Ä–æ–∑—Ä–∞—á–Ω–æ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
- ‚úÖ –≠–∫–æ–Ω–æ–º–∏—Ç —Ç–æ–∫–µ–Ω—ã

---

### –í–∞—Ä–∏–∞–Ω—Ç 3: –†–µ–∂–∏–º —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ (30 –º–∏–Ω—É—Ç)

**–î–æ–±–∞–≤–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä `mode` –¥–ª—è —è–≤–Ω–æ–≥–æ –∫–æ–Ω—Ç—Ä–æ–ª—è:**

```python
# –í backend/app.py

class AskRequest(BaseModel):
    q: str
    space_id: Optional[str] = None
    top_k: int = config.TOP_K_DEFAULT
    doc_types: Optional[List[str]] = None
    mode: str = "normal"  # NEW: "normal" | "summarize"

@app.post("/ask")
def ask(req: AskRequest = Body(...)):
    # ... search logic ...
    fused = _limit_one_chunk_per_doc(candidate_pool, effective_top_k)
    
    if req.mode == "summarize":
        # Explicit summarization mode
        summary = summarize_chunks(fused, query=req.q)
        
        prompt = f"Based on this summary:\n\n{summary}\n\nAnswer: {req.q}"
        answer = call_llm(prompt)
        
        return {
            "answer": answer,
            "summary": summary,  # Include summary in response
            "mode": "summarize",
            "sources": [...]
        }
    else:
        # Normal mode
        prompt = build_prompt(fused, req.q)
        answer = call_llm(prompt)
        return {"answer": answer, "mode": "normal", "sources": [...]}
```

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
```bash
# Normal RAG
curl -X POST http://localhost:8000/ask \
  -d '{"q":"What are the deadlines?","space_id":"demo","mode":"normal"}'

# With summarization
curl -X POST http://localhost:8000/ask \
  -d '{"q":"What are the deadlines?","space_id":"demo","mode":"summarize"}'
```

---

### –í–∞—Ä–∏–∞–Ω—Ç 4: –°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –ø—Ä–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ (45 –º–∏–Ω—É—Ç)

**–°–æ–∑–¥–∞–≤–∞—Ç—å summary —á–∞–Ω–∫ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞:**

```python
# –í backend/app.py, –≤ —Ñ—É–Ω–∫—Ü–∏–∏ ingest():

from services.summarization import summarize_text_sync

@app.post("/ingest")
async def ingest(
    space_id: str = Form(...),
    file: UploadFile = File(...),
    doc_type: Optional[str] = Form(None),
    create_summary: bool = Form(True),  # NEW: create summary by default
):
    # ... parsing logic ...
    text = _parse(file.filename, await file.read())
    chunks = split_markdown(text)
    
    # NEW: Create summary if document is large
    summary = None
    text_tokens = len(text.split())
    
    if create_summary and text_tokens > 2000:
        print(f"[Ingest] Creating summary for {file.filename} ({text_tokens} tokens)...")
        
        summary = summarize_text_sync(text, max_summary_tokens=500)
        
        # Add summary as first chunk with special marker
        summary_chunk = f"[DOCUMENT SUMMARY]\n\n{summary}\n\n[/DOCUMENT SUMMARY]"
        chunks.insert(0, summary_chunk)
    
    # Index chunks (including summary if created)
    upsert_chunks(space_id, doc_id, norm_doc_type, chunks)
    
    return {
        "doc_id": doc_id,
        "chunks_indexed": len(chunks),
        "summary": summary,
        "has_summary": summary is not None
    }
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- ‚úÖ Summary –≤—Å–µ–≥–¥–∞ –¥–æ—Å—Ç—É–ø–Ω–∞ (–≤ –∏–Ω–¥–µ–∫—Å–µ)
- ‚úÖ –ú–æ–∂–Ω–æ –Ω–∞–π—Ç–∏ —á–µ—Ä–µ–∑ –ø–æ–∏—Å–∫
- ‚úÖ –û–¥–∏–Ω —Ä–∞–∑ —Å–æ–∑–¥–∞–µ–º, –º–Ω–æ–≥–æ —Ä–∞–∑ –∏—Å–ø–æ–ª—å–∑—É–µ–º

**–ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏:**
- ‚ùå –î–æ–ª—å—à–µ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è
- ‚ùå –ë–æ–ª—å—à–µ –º–µ—Å—Ç–∞ –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –ë–î

---

### –í–∞—Ä–∏–∞–Ω—Ç 5: Email thread —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è (30 –º–∏–Ω—É—Ç)

**–°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π endpoint –¥–ª—è email –ø–µ—Ä–µ–ø–∏—Å–∫–∏:**

```python
# –í backend/app.py

@app.get("/summarize/emails")
def summarize_emails(
    space_id: str,
    topic: Optional[str] = None,
    date_from: Optional[str] = None,
    date_to: Optional[str] = None
):
    """
    Summarize email correspondence
    
    Example: /summarize/emails?space_id=acme&topic=cloud migration
    """
    # Search emails
    query = topic or "all correspondence"
    results = semantic_search(
        query,
        space_id,
        doc_types=["email_correspondence"],
        top_k=100
    )
    
    if not results:
        return {"summary": "No emails found"}
    
    # Group by doc_id (email thread)
    threads = {}
    for r in results:
        doc_id = r["payload"]["doc_id"]
        if doc_id not in threads:
            threads[doc_id] = {
                "doc_id": doc_id,
                "chunks": []
            }
        threads[doc_id]["chunks"].append(r["payload"]["text"])
    
    # Summarize each thread
    thread_summaries = []
    for thread_id, thread_data in threads.items():
        thread_text = "\n\n---\n\n".join(thread_data["chunks"])
        
        summary = summarize_text_sync(
            thread_text,
            max_summary_tokens=200,
            focus=topic
        )
        
        thread_summaries.append({
            "thread_id": thread_id,
            "messages": len(thread_data["chunks"]),
            "summary": summary
        })
    
    # Overall summary
    all_text = "\n\n".join([
        f"Thread {i+1}: {s['summary']}"
        for i, s in enumerate(thread_summaries)
    ])
    
    overall = summarize_text_sync(
        all_text,
        max_summary_tokens=500,
        focus=topic
    )
    
    return {
        "topic": topic,
        "threads_analyzed": len(thread_summaries),
        "overall_summary": overall,
        "thread_summaries": thread_summaries
    }
```

**–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:**
```bash
# –°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö email –ø—Ä–æ "cloud migration"
curl "http://localhost:8000/summarize/emails?space_id=acme&topic=cloud%20migration"
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**
```json
{
  "topic": "cloud migration",
  "threads_analyzed": 5,
  "overall_summary": "Email discussions about cloud migration focused on: 1) Budget approval of $200K (March 5), 2) Technology selection: Kubernetes + AWS (March 12), 3) Timeline concerns raised by team (March 18-25), 4) Risk assessment of data migration (March 22), 5) Team formation: 5 engineers assigned (March 30)",
  "thread_summaries": [
    {
      "thread_id": "email_thread_001",
      "messages": 15,
      "summary": "Budget discussion. John proposed $200K, approved by management March 5"
    },
    ...
  ]
}
```

---

## üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤

| –í–∞—Ä–∏–∞–Ω—Ç | –°–ª–æ–∂–Ω–æ—Å—Ç—å | –í—Ä–µ–º—è | –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å |
|---------|-----------|-------|-------------------|
| **1. –ù–æ–≤—ã–π endpoint** | ‚≠ê –ü—Ä–æ—Å—Ç–∞—è | 5 –º–∏–Ω | –ë–∞–∑–æ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å |
| **2. Auto –≤ RAG** | ‚≠ê‚≠ê –°—Ä–µ–¥–Ω—è—è | 15 –º–∏–Ω | –ü—Ä–æ–∑—Ä–∞—á–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è |
| **3. –†–µ–∂–∏–º —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏** | ‚≠ê‚≠ê –°—Ä–µ–¥–Ω—è—è | 30 –º–∏–Ω | –ö–æ–Ω—Ç—Ä–æ–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º |
| **4. –ü—Ä–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏** | ‚≠ê‚≠ê‚≠ê –°–ª–æ–∂–Ω–∞—è | 45 –º–∏–Ω | –û–¥–∏–Ω —Ä–∞–∑ —Å–æ–∑–¥–∞—Ç—å, –º–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å |
| **5. Email threads** | ‚≠ê‚≠ê‚≠ê –°–ª–æ–∂–Ω–∞—è | 30 –º–∏–Ω | –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–π use case |

---

## üéØ –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π –ø–ª–∞–Ω –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏

### –≠—Ç–∞–ø 1: –ë–∞–∑–æ–≤–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è (30 –º–∏–Ω—É—Ç)

```bash
# 1. –§–∞–π–ª —É–∂–µ —Å–æ–∑–¥–∞–Ω
# backend/services/summarization.py ‚úÖ

# 2. –î–æ–±–∞–≤–∏—Ç—å –≤ app.py
```

**–î–æ–±–∞–≤–∏—Ç—å –≤ `backend/app.py`:**

```python
# –í –Ω–∞—á–∞–ª–µ —Ñ–∞–π–ª–∞
from services.summarization import (
    summarize_text_sync,
    summarize_long_text_sync,
    summarize_document_by_id,
)

# –î–æ–±–∞–≤–∏—Ç—å endpoint
@app.post("/summarize")
def summarize_document(
    doc_id: str = Body(...),
    space_id: str = Body(...),
    focus: Optional[str] = Body(None)
):
    """–°—É–º–º–∞—Ä–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç"""
    summary = summarize_document_by_id(doc_id, space_id, focus)
    return {"doc_id": doc_id, "summary": summary}
```

**–¢–µ—Å—Ç:**
```bash
# –ü–æ—Å–ª–µ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞
DOC_ID=$(curl -X POST http://localhost:8000/ingest \
  -F "file=@test.pdf" \
  -F "space_id=demo" | jq -r .doc_id)

# –°—É–º–º–∞—Ä–∏–∑–∏—Ä–æ–≤–∞—Ç—å
curl -X POST http://localhost:8000/summarize \
  -H "Content-Type: application/json" \
  -d "{\"doc_id\":\"$DOC_ID\",\"space_id\":\"demo\"}"
```

---

### –≠—Ç–∞–ø 2: Smart context compression (15 –º–∏–Ω—É—Ç)

**–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å—É–º–º–∞—Ä–∏–∑–∏—Ä–æ–≤–∞—Ç—å –µ—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π:**

```python
# –í backend/app.py, –æ–±–Ω–æ–≤–∏—Ç—å —Ñ—É–Ω–∫—Ü–∏—é ask():

from services.summarization import summarize_chunks

@app.post("/ask")
def ask(req: AskRequest = Body(...)):
    # ... existing logic –¥–æ prompt building ...
    
    # NEW: –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    context_tokens = _count_context_tokens(fused)
    max_context_tokens = 4000  # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–π –ª–∏–º–∏—Ç
    
    if context_tokens > max_context_tokens:
        # –°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –ø–µ—Ä–µ–¥ RAG
        summary = summarize_chunks(fused, query=req.q, max_output_tokens=2000)
        
        prompt = (
            "–¢—ã ‚Äî –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –æ—Ç–≤–µ—á–∞–π —Å—Ç—Ä–æ–≥–æ –ø–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–º—É –ö–û–ù–¢–ï–ö–°–¢–£.\n\n"
            f"–ö–û–ù–¢–ï–ö–°–¢ (summarized from {len(fused)} chunks):\n{summary}\n\n"
            f"–í–û–ü–†–û–°:\n{req.q}\n\n"
            "–û—Ç–≤–µ—Ç—å –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É."
        )
    else:
        prompt = build_prompt(fused, req.q)
    
    answer = call_llm(prompt)
    # ... rest of logic ...
```

**–≠—Ñ—Ñ–µ–∫—Ç:**
- –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –∑–∞–º–µ—á–∞–µ—Ç —Ä–∞–∑–Ω–∏—Ü—ã
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –±–æ–ª—å—à–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã
- –≠–∫–æ–Ω–æ–º–∏—è —Ç–æ–∫–µ–Ω–æ–≤ LLM

---

### –≠—Ç–∞–ø 3: Email thread summarization (30 –º–∏–Ω—É—Ç)

**–°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π endpoint –¥–ª—è –≤–∞—à–∏—Ö email:**

```python
# –í backend/app.py

@app.get("/summarize/emails")
def summarize_email_threads(
    space_id: str,
    topic: Optional[str] = None
):
    """–°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è email –ø–µ—Ä–µ–ø–∏—Å–∫–∏"""
    
    # –ü–æ–∏—Å–∫ emails
    results = semantic_search(
        topic or "all",
        space_id,
        doc_types=["email_correspondence"],
        top_k=50
    )
    
    # Group by doc_id
    threads = {}
    for r in results:
        doc_id = r["payload"]["doc_id"]
        if doc_id not in threads:
            threads[doc_id] = []
        threads[doc_id].append(r["payload"]["text"])
    
    # Summarize each thread
    summaries = []
    for doc_id, chunks in threads.items():
        thread_text = "\n\n".join(chunks)
        summary = summarize_text_sync(thread_text, max_summary_tokens=200)
        summaries.append({"thread_id": doc_id, "summary": summary})
    
    # Overall summary
    all_summaries = "\n\n".join([s["summary"] for s in summaries])
    overall = summarize_text_sync(all_summaries, max_summary_tokens=500, focus=topic)
    
    return {
        "topic": topic,
        "threads": len(summaries),
        "overall_summary": overall,
        "thread_summaries": summaries
    }
```

**–ü—Ä–∏–º–µ—Ä:**
```bash
curl "http://localhost:8000/summarize/emails?space_id=demo&topic=project%20deadlines"
```

---

## üîß –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

### –î–æ–±–∞–≤–∏—Ç—å –≤ config.py

```python
# backend/services/config.py

# Summarization settings
SUMMARIZATION_ENABLED = os.getenv("SUMMARIZATION_ENABLED", "true").lower() == "true"
SUMMARIZATION_CHUNK_SIZE = int(os.getenv("SUMMARIZATION_CHUNK_SIZE", "8000"))
SUMMARIZATION_MAX_SUMMARY_TOKENS = int(os.getenv("SUMMARIZATION_MAX_SUMMARY_TOKENS", "500"))
SUMMARIZATION_AUTO_THRESHOLD = int(os.getenv("SUMMARIZATION_AUTO_THRESHOLD", "4000"))
```

### –î–æ–±–∞–≤–∏—Ç—å –≤ .env

```bash
# Summarization
SUMMARIZATION_ENABLED=true
SUMMARIZATION_CHUNK_SIZE=8000          # –†–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ –¥–ª—è MAP phase
SUMMARIZATION_MAX_SUMMARY_TOKENS=500   # –ú–∞–∫—Å —Ç–æ–∫–µ–Ω–æ–≤ –≤ summary
SUMMARIZATION_AUTO_THRESHOLD=4000      # –ê–≤—Ç–æ-—Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –µ—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç > —ç—Ç–æ–≥–æ
```

---

## üìù –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### –ü—Ä–∏–º–µ—Ä 1: –°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –¥–ª–∏–Ω–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞

```python
# Python client
import requests

# –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç
response = requests.post(
    "http://localhost:8000/ingest",
    files={"file": open("long_spec.pdf", "rb")},
    data={"space_id": "demo"}
)
doc_id = response.json()["doc_id"]

# –°—É–º–º–∞—Ä–∏–∑–∏—Ä–æ–≤–∞—Ç—å
summary_response = requests.post(
    "http://localhost:8000/summarize",
    json={
        "doc_id": doc_id,
        "space_id": "demo",
        "focus": "technical requirements"
    }
)

print(summary_response.json()["summary"])
```

### –ü—Ä–∏–º–µ—Ä 2: RAG —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–µ–π

```python
# –ó–∞–ø—Ä–æ—Å —Å –±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
response = requests.post(
    "http://localhost:8000/ask",
    json={
        "q": "Tell me about all cloud migration discussions",
        "space_id": "demo",
        "top_k": 20  # –ú–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    }
)

# Backend –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏:
# 1. –ù–∞–π–¥–µ—Ç 20 —á–∞–Ω–∫–æ–≤
# 2. –û–ø—Ä–µ–¥–µ–ª–∏—Ç —á—Ç–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç > 4000 tokens
# 3. –°—É–º–º–∞—Ä–∏–∑–∏—Ä—É–µ—Ç —á–∞–Ω–∫–∏
# 4. –û—Ç–≤–µ—Ç–∏—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ summary

print(response.json()["answer"])
```

### –ü—Ä–∏–º–µ—Ä 3: Email thread summary

```python
# –°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö email –ø—Ä–æ –ø—Ä–æ–µ–∫—Ç
response = requests.get(
    "http://localhost:8000/summarize/emails",
    params={
        "space_id": "demo",
        "topic": "project alpha"
    }
)

summary = response.json()
print(f"Found {summary['threads']} email threads")
print(f"\nOverall: {summary['overall_summary']}")

for thread in summary["thread_summaries"]:
    print(f"\nThread {thread['thread_id']}: {thread['summary']}")
```

---

## üé® UI Integration –ø—Ä–∏–º–µ—Ä—ã

### –ö–Ω–æ–ø–∫–∞ "Summarize" –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞

```typescript
// Frontend TypeScript
async function summarizeDocument(docId: string, spaceId: string) {
  const response = await fetch('/summarize', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ doc_id: docId, space_id: spaceId })
  });
  
  const { summary } = await response.json();
  return summary;
}

// –í UI
<button onClick={() => {
  const summary = await summarizeDocument(doc.id, workspace.id);
  showModal("Document Summary", summary);
}}>
  üìÑ Summarize
</button>
```

### Toggle –¥–ª—è —Ä–µ–∂–∏–º–∞ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏

```typescript
// –í chat interface
const [mode, setMode] = useState<'normal' | 'summarize'>('normal');

async function askQuestion(question: string) {
  const response = await fetch('/ask', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      q: question,
      space_id: workspace.id,
      mode: mode  // 'normal' or 'summarize'
    })
  });
  
  return response.json();
}

// UI
<label>
  <input 
    type="checkbox" 
    checked={mode === 'summarize'}
    onChange={(e) => setMode(e.target.checked ? 'summarize' : 'normal')}
  />
  Use summarization mode (better for broad questions)
</label>
```

---

## ‚ö° Performance considerations

### –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è

```python
# –ü—Ä–æ—Å—Ç–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è (< 4K tokens)
Time: ~2-5 seconds
LLM calls: 1

# Map-Reduce (100K tokens, 10 chunks)
Time: ~20-50 seconds (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –º–æ–∂–Ω–æ ~10-15s)
LLM calls: 11 (10 MAP + 1 REDUCE)

# Email threads (5 threads)
Time: ~10-25 seconds
LLM calls: 6 (5 threads + 1 overall)
```

### –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è: –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞

```python
# –í summarization.py –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å:

import asyncio

async def summarize_long_text_parallel(text: str, chunk_size: int = 8000) -> str:
    """Map-Reduce —Å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π MAP —Ñ–∞–∑–æ–π"""
    
    chunks = split_text_by_tokens(text, max_tokens=chunk_size)
    
    # MAP PHASE: –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
    async def summarize_chunk(i, chunk):
        print(f"[Worker {i}] Summarizing...")
        return await summarize_text(chunk, max_summary_tokens=300)
    
    # –ó–∞–ø—É—Å—Ç–∏—Ç—å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
    tasks = [summarize_chunk(i, chunk) for i, chunk in enumerate(chunks, 1)]
    summaries = await asyncio.gather(*tasks)
    
    # REDUCE PHASE
    combined = "\n\n".join(summaries)
    return await summarize_text(combined, max_summary_tokens=800)
```

**–£—Å–∫–æ—Ä–µ–Ω–∏–µ:** 3-5x –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤

---

## üêõ –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫

```python
# –í summarization.py

async def summarize_text(text: str, max_summary_tokens: int = 500) -> str:
    """–°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—É—Å—Ç–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
    if not text or not text.strip():
        return "[Empty document - nothing to summarize]"
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞
    tokens = count_tokens_simple(text)
    if tokens < 50:
        return text  # Too short to summarize, return as-is
    
    try:
        prompt = f"Summarize concisely:\n\n{text}\n\nSUMMARY:"
        summary = call_llm(prompt)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        if not summary or summary.startswith("[LLM"):
            return f"[Summarization failed: {summary}]"
        
        return summary.strip()
        
    except Exception as e:
        return f"[Summarization error: {str(e)}]"
```

---

## üìö –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è API

### POST /summarize

**Request:**
```json
{
  "doc_id": "migration_plan_abc123",
  "space_id": "company_acme",
  "focus": "budget and timeline"  // optional
}
```

**Response:**
```json
{
  "doc_id": "migration_plan_abc123",
  "summary": "Cloud migration plan overview: Budget $200K, Timeline 6 months..."
}
```

### POST /ask (—Å —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–µ–π)

**Request:**
```json
{
  "q": "What are all the cloud migration plans?",
  "space_id": "company_acme",
  "top_k": 20,
  "mode": "summarize"  // NEW: explicit summarization
}
```

**Response:**
```json
{
  "answer": "Based on the documents, there are 3 migration plans...",
  "summary": "Summary of 20 relevant chunks: ...",  // NEW
  "mode": "summarize",
  "sources": [...]
}
```

### GET /summarize/emails

**Request:**
```
GET /summarize/emails?space_id=demo&topic=project%20alpha
```

**Response:**
```json
{
  "topic": "project alpha",
  "threads_analyzed": 5,
  "overall_summary": "Email discussions covered...",
  "thread_summaries": [
    {
      "thread_id": "email_001",
      "messages": 15,
      "summary": "Budget discussion..."
    }
  ]
}
```

---

## üéâ –ì–æ—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã

### 1. –°–µ—Ä–≤–∏—Å —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
üìÅ `backend/services/summarization.py` ‚úÖ –°–æ–∑–¥–∞–Ω

**–§—É–Ω–∫—Ü–∏–∏:**
- `summarize_text()` - –ø—Ä–æ—Å—Ç–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è
- `summarize_long_text()` - map-reduce
- `summarize_chunks()` - –¥–ª—è search results
- `summarize_document_by_id()` - –ø–æ doc_id

### 2. –ü—Ä–∏–º–µ—Ä—ã –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
üìÅ `backend/app_with_summarization.py` ‚úÖ –°–æ–∑–¥–∞–Ω

**–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç:**
- 5 –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
- API endpoints
- –ì–æ—Ç–æ–≤—ã–π –∫–æ–¥ –¥–ª—è –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è

### 3. –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
üìÅ `docs/SUMMARIZATION_INTEGRATION_GUIDE.md` ‚úÖ –°–æ–∑–¥–∞–Ω

---

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### –®–∞–≥ 1: –°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥—É–ª—å (—É–∂–µ –≥–æ—Ç–æ–≤)
```bash
# backend/services/summarization.py —É–∂–µ —Å–æ–∑–¥–∞–Ω ‚úÖ
```

### –®–∞–≥ 2: –î–æ–±–∞–≤–∏—Ç—å –≤ app.py (30 —Å—Ç—Ä–æ–∫ –∫–æ–¥–∞)

```python
# –í –Ω–∞—á–∞–ª–µ backend/app.py
from services.summarization import summarize_document_by_id

# –î–æ–±–∞–≤–∏—Ç—å endpoint
@app.post("/summarize")
def summarize_document(
    doc_id: str = Body(...),
    space_id: str = Body(...),
    focus: Optional[str] = Body(None)
):
    summary = summarize_document_by_id(doc_id, space_id, focus)
    return {"doc_id": doc_id, "summary": summary}
```

### –®–∞–≥ 3: –¢–µ—Å—Ç

```bash
# 1. –ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç
make ingest

# 2. –ü–æ–ª—É—á–∏—Ç—å doc_id
curl http://localhost:8000/search?q=test&space_id=space_demo | jq '.results[0].payload.doc_id'

# 3. –°—É–º–º–∞—Ä–∏–∑–∏—Ä–æ–≤–∞—Ç—å
curl -X POST http://localhost:8000/summarize \
  -H "Content-Type: application/json" \
  -d '{"doc_id":"<DOC_ID>","space_id":"space_demo"}'
```

---

## üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è

**–ù–∞—á–Ω–∏—Ç–µ —Å –í–∞—Ä–∏–∞–Ω—Ç–∞ 1 + –í–∞—Ä–∏–∞–Ω—Ç–∞ 2:**

1. ‚úÖ **–í–∞—Ä–∏–∞–Ω—Ç 1** (5 –º–∏–Ω) - –±–∞–∑–æ–≤—ã–π `/summarize` endpoint
2. ‚úÖ **–í–∞—Ä–∏–∞–Ω—Ç 2** (15 –º–∏–Ω) - –∞–≤—Ç–æ-—Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –≤ `/ask` –µ—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –±–æ–ª—å—à–æ–π

**–ò—Ç–æ–≥–æ:** 20 –º–∏–Ω—É—Ç —Ä–∞–±–æ—Ç—ã, –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏!

**–ü–æ–∑–∂–µ –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å:**
- –í–∞—Ä–∏–∞–Ω—Ç 5 (email threads) - –¥–ª—è –≤–∞—à–µ–π email_correspondence
- –í–∞—Ä–∏–∞–Ω—Ç 4 (–ø—Ä–∏ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏) - –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –∫—ç—à–∏—Ä–æ–≤–∞—Ç—å summaries

–ì–æ—Ç–æ–≤—ã –Ω–∞—á–∞—Ç—å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é?

