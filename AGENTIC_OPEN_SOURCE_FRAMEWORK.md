# Сравнение open-source фреймворков под вашу архитектуру

Ниже — практичный обзор трёх стеков с акцентом на **мультиагентную архитектуру с маршрутизацией**, **офлайн-RAG**, **SGR/строго структурированные ответы**, **vLLM/Ollama**, **Qdrant/OpenSearch**, **gRPC/WebSocket**, **наблюдаемость (OTel/Prometheus/Grafana/Jaeger/Langfuse)**.

---

## Haystack

### Плюсы для вашей архитектуры

* **Пайплайны (DAG) и компоненты**: удобно собирать **промышленный RAG-конвейер** (ingest → retriever → rerank → synthesize), есть визуализация/дебаг, легко «упаковать» как сервис.
* **Agents & Tools**: есть агент как «tool-loop», можно **вложить пайплайн в Tool** и вызвать из агента. Нормально ложится в паттерн *Router → специализированные агенты*.
* **Поддержка локальных LLM**: HF Transformers (локально), llama.cpp/GGUF, Ollama; или **OpenAI-совместимые** эндпоинты (vLLM/TGI) — без переписывания пайплайна.
* **Широкая экосистема коннекторов**: Qdrant/Weaviate/Milvus, Elastic/OpenSearch, файлы/базы.
* **Производственная ориентация**: хорош для **интеграции и эксплуатации** (ретрай, трейсинг вокруг пайплайна, тестирование).

### Минусы/ограничения

* **Сложные графы рассуждений** (долгоживущие, с чекпоинтами, ветвлениями) делать можно, но **оркестрация в глубину** потребует больше кода/обвязки, чем в LangGraph.
* **Мультиагентность** есть, но для **богатых диалогов/ролей** и «долгих» ветвящихся сценариев проще сочетать с внешним граф-движком.

### Agent Design Patterns «из коробки»

* **ReAct-подобные циклы** (агент вызывает Tools, анализирует результат).
* **Router → Specialists** (через pipeline-tools/агенты).
* **RAG-конвейер** (retrieval → rerank → synthesis).
* **Function/Tool-calling** (обёртывание функций/пайплайнов в инструменты).
* **CoT/Plan-and-Execute** — собирается через цепочки компонентов (не как «готовый класс», а как композиция шагов).

### Лицензия

* **Apache-2.0** (open-source, совместим с коммерческим использованием).

### Место в вашей архитектуре

* **RAG/пайплайны и документы** (ingest, hybrid-retrieval, rerank).
* **Сервис Retrieval** с gRPC/REST (Qdrant+OpenSearch+Reranker).
* **Агенты-инструменты** для Router/Orchestrator (Go вызывает Haystack-сервис).

### Взаимозаменяемость

* Используйте **OpenAI-совместимый API** для LLM (vLLM/TGI) и **унифицированные REST/gRPC**-контракты на Retrieval — тогда можно менять Haystack ↔︎ LlamaIndex без ломки.
* Храните **модели и индексы отдельно** (Qdrant/OpenSearch вне фреймворка), а сервисы строите поверх.

### Синергия при совместном использовании

* **Haystack = производственный RAG** (конвейер + коннекторы), а **LangGraph/LlamaIndex = оркестрация/агентные шаги**. Вы получаете лучший из двух миров: стабильный Retrieval-сервис + гибкие графы рассуждений.

---

## LlamaIndex

### Плюсы для вашей архитектуры

* **Workflows / Query Pipelines / Routers**: изящный способ выразить **сложные графы** (событийные шаги, ветвления, циклы), удобно для **агентных сценариев** (ReAct-петли, подсценарии).
* **Сильный RAG-стек**: query-engine’ы, комбинированные ретриверы, индексные структуры, composable графы извлечения (мульти-док).
* **Интеграции с локальными/частными LLM**: HF локально, Ollama, OpenAI-совместимые (vLLM/TGI).
* **Простая композиция Router → Specialized chains**: удобно строить **специализированных агентов** как Workflows/Query Englines и подключать к Router.

### Минусы/ограничения

* **Продукционная эксплуатация** (long-running durability, time-travel, параллельность) требует **доп. чекпоинтинга/стора** и/или сочетания с внешним оркестратором (Temporal / ваш Go state-machine / LangGraph).
* Меньше «готовых» интеграций enterprise-класса для наблюдаемости, чем в Haystack (решается OTel/Langfuse, но больше ручной работы).

### Agent Design Patterns «из коробки»

* **ReAct/Tool-Use** (агенты с инструментами).
* **Routers** (ветвление по веткам/специалистам).
* **Query Pipelines / DAG** (LLM → ретрив → синтез).
* **Workflows** (пошаговые графы c контекстом/состоянием, чекпоинты).
* **Plan-and-Execute** — через Workflows/пайплайны (план → исполнение).

### Лицензия

* **MIT** (open-source, свободно для коммерции).

### Место в вашей архитектуре

* **Агентные цепочки** (RAG-Agent, Summarizer/Report-Agent) как Workflows.
* **Маршрутизатор** (Python-runtime) в составе Orchestrator, либо как подчинённый модуль.
* Можно заменить/дополнить Haystack в **Retrieval-сервисе** (интеграции с Qdrant/OpenSearch есть).

### Взаимозаменяемость

* Стандартизируйте **интерфейсы сервисов** (gRPC protobuf) + **OpenAI-совм. LLM**, храните индексы в Qdrant/OpenSearch.
* Тогда LlamaIndex ↔︎ Haystack «меняются» на уровне микросервисов без затрагивания Router/LLM.

### Синергия при совместном использовании

* **LlamaIndex = гибкие Workflows/агенты**, **Haystack = RAG-конвейер/коннекторы**. Напр., RAG-сервис — Haystack, а **агентные Workflows** и сложные роутинги — LlamaIndex.

---

## LangGraph / LangChain

### Плюсы для вашей архитектуры

* **LangGraph**: граф-движок для **долгоживущих состояний**, **чекпоинтов**, **ветвлений**, **параллельности**, **human-in-the-loop**. Легко «разложить» рассуждение на **state-machine**. Отличная база под **Router/Orchestrator**.
* **LangChain**: огромная экосистема **агентных паттернов**, **Tools**, интеграций (векторки/БД/облака), быстрый прототипинг.
* **Checkpointers** (SQLite/Postgres/Redis): **персистентность** шагов, в т.ч. для «возобновления» процессов, time-travel.
* Нативное **инструментальное/агентное мышление**: ReAct, MRKL, Plan-and-Execute, Tool-calling, Multi-agent (через граф).

### Минусы/ограничения

* **Ставка на Python** (для ядра графа); если оркестратор у вас в **Go**, нужна граница по gRPC/REST (впрочем, это ок).
* **Из коробки** Retrieval-конвейер не столь «промышленный», как в Haystack — обычно подключают Retriever как внешний сервис (что для вас и планируется).

### Agent Design Patterns «из коробки»

* **ReAct**, **Plan-and-Execute**, **Conversational/Tool Agents**, **MRKL**, **Router → Specialists**, **CoT/ToT/Reflexion** (собираются через граф узлов).
* **Human-in-the-loop**, **параллельные ветви**, **контроль переходов** (LangGraph).

### Лицензия

* **MIT** (open-source, можно в коммерцию).
  *(Платформенный сервер LangGraph — коммерческий, библиотека — MIT.)*

### Место в вашей архитектуре

* **Orchestration & агенты (ядро)**: Router/Orchestrator, планирование, чекпоинты, многоветвевые сценарии.
* **State & Memory**: Postgres/Redis через checkpointer.
* Вызывает **внешние сервисы**: Retrieval (Haystack/LlamaIndex-сервис), SGR/Formatter, Tools-Gateway, LLM (vLLM/Ollama).

### Взаимозаменяемость

* Явная **граница по gRPC**: Router (LangGraph) вызывает Retrieval/SGR/LLM как сервисы → можно менять Haystack/LlamaIndex без изменений графа.
* Миграция **в Go**: графовую логику можно перенести в Go-state-machine, оставив контракты неизменными.

### Синергия при совместном использовании

* **LangGraph = оркестрация/граф**, **Haystack/LlamaIndex = RAG и агенты-исполнители**.
  Вы получаете контролируемые процессы (чекпоинты/ветвления) + зрелые RAG-конвейеры и инструменты.

---

## Суммарная таблица

| Критерий                            | **Haystack**                                        | **LlamaIndex**                                            | **LangGraph/LangChain**                                      |
| ----------------------------------- | --------------------------------------------------- | --------------------------------------------------------- | ------------------------------------------------------------ |
| Фокус                               | Промышленный RAG-конвейер, интеграции, агенты-tools | Workflows/Query Pipelines/Routers для гибких графов + RAG | Граф-движок рассуждений/состояний + тонна агентных паттернов |
| Сложные графы/долгоживущие процессы | 🟡 (через обвязку)                                  | ✅ (Workflows + checkpointing)                             | ✅✅ (LangGraph: state, checkpoints, parallel)                 |
| Мультиагентность/Router→Specialists | ✅                                                   | ✅                                                         | ✅✅                                                           |
| Retrieval/коннекторы (Qdrant/OS)    | ✅✅                                                  | ✅                                                         | 🟡 (через интеграции; чаще выносить в сервис)                |
| SGR/структурирование                | через Tools/обёртки                                 | через Tools/Workflows                                     | через Tools/узлы графа                                       |
| Локальные LLM (HF/llama.cpp/Ollama) | ✅                                                   | ✅                                                         | ✅                                                            |
| OpenAI-совм. (vLLM/TGI)             | ✅                                                   | ✅                                                         | ✅                                                            |
| Лицензия                            | Apache-2.0                                          | MIT                                                       | MIT (библиотека)                                             |
| Лучшая роль в вашей схеме           | **RAG-сервис**                                      | **Агент-workflows** / альтернативный RAG                  | **Router/Orchestrator** (ядро)                               |

---

## Рекомендации по раскладке в вашей архитектуре

* **Orchestration & агенты (ядро)** → **LangGraph** (MIT) + ваш REST/gRPC Router (Go).
* **RAG/пайплайны** → **Haystack** (Apache-2.0) как отдельный Retrieval-сервис (ingest, hybrid, rerank).
  *(Альтернатива/смешанный режим — LlamaIndex, особенно если нужны гибкие Workflows прямо в RAG.)*
* **SGR/Formatter** → Outlines/Guardrails/Instructor как самостоятельный сервис, вызываемый графом.
* **LLM** → **vLLM** (OpenAI-совм.) как основной; **Ollama** для офлайн-R&D.
* **Наблюдаемость** → OTel + Prometheus/Grafana + Jaeger + Langfuse для логов промптов/шагов.

Такой «разделённый» дизайн:

* оставляет **взаимозаменяемость** (RAG-сервис можно сменить Haystack ↔︎ LlamaIndex, не трогая Router/граф);
* изолирует **модельный сервис** (vLLM/Ollama) от оркестрации;
* делает **SGR** самостоятельным, чтобы легко обновлять правила/схемы;
* упрощает эксплуатацию (каждый сервис — свой SLA, свои ресурсы).

---

## Когда использовать совместно

* **LangGraph + Haystack**: граф-логика/чекпоинты + зрелый RAG-конвейер и коннекторы к поиску/БД.
* **LangGraph + LlamaIndex**: если RAG требует **нестандартных Workflows/routers** и «алгебры запросов».
* **Haystack + LlamaIndex**: редко, но полезно, когда **ingest/коннекторы** удобнее в Haystack, а **запросные цепочки** — в LlamaIndex; при этом оба работают как микросервисы за gRPC/REST.

---

## Практический чек-лист взаимозаменяемости

1. **Контракты сервисов** (protobuf/REST): `Retrieval.Search`, `Retrieval.Ingest`, `Formatter.Format`, `LLM.Chat`, `LLM.Embed`, `Reranker.Rerank`.
2. **Единые схемы** для payload (doc_id, space_id, metadata, citations).
3. **OpenAI-совм. API** для LLM (vLLM) — чтобы агенты не зависели от SDK.
4. **Qdrant/OpenSearch вне фреймворков** (как управляемые сервисы).
5. **OTel** в каждом сервисе: trace-id сквозной от Gateway → Router → агентов → Retrieval/LLM/SGR.

Если хочешь — соберу короткий **пример контрактов (protobuf)** и **Compose-файл** с тремя вариантами RAG-сервиса (Haystack/LlamaIndex stub), переключаемыми флагом окружения.
