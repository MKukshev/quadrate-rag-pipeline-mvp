# Configuration for vLLM (GPU required)
LLM_MODE=vllm
LLM_VLLM_URL=http://vllm:8001/v1
LLM_MODEL=meta-llama/Meta-Llama-3.1-8B-Instruct
LLM_TIMEOUT=120
LLM_MAX_TOKENS=512
LLM_TEMPERATURE=0.7
VLLM_MODEL=meta-llama/Meta-Llama-3.1-8B-Instruct
VLLM_GPU_MEMORY_UTILIZATION=0.90
VLLM_MAX_MODEL_LEN=8192
VLLM_TENSOR_PARALLEL_SIZE=1
HUGGING_FACE_HUB_TOKEN=your_token_here
QDRANT_URL=http://qdrant:6333
EMBED_MODEL=sentence-transformers/all-MiniLM-L6-v2
