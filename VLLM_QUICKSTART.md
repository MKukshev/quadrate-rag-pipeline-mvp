# vLLM Quick Start –¥–ª—è RTX 6000 Blackwell 96GB

## üöÄ –ë—ã—Å—Ç—Ä—ã–π –∑–∞–ø—É—Å–∫ (3 –∫–æ–º–∞–Ω–¥—ã)

```bash
# 1. –°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é vLLM
cp .env.vllm .env

# 2. –î–æ–±–∞–≤–∏—Ç—å HuggingFace —Ç–æ–∫–µ–Ω –≤ .env
nano .env  # HUGGING_FACE_HUB_TOKEN=hf_xxxxx

# 3. –ó–∞–ø—É—Å—Ç–∏—Ç—å
make up-vllm
```

## üìä –ß—Ç–æ –ø–æ–ª—É—á–∏—Ç–µ

- ‚ö° **150-250 tokens/sec** (vs 40-60 –Ω–∞ Ollama)
- üöÄ **15-30 requests/sec** throughput
- ‚è±Ô∏è **0.1-0.3s** first token latency
- üíæ –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ 96GB VRAM

## üîÑ –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –º–µ–∂–¥—É Ollama –∏ vLLM

```bash
# –ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å—Å—è –Ω–∞ vLLM (GPU)
make switch-vllm

# –í–µ—Ä–Ω—É—Ç—å—Å—è –∫ Ollama (CPU/GPU)
make switch-ollama
```

## üéØ –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –º–æ–¥–µ–ª–∏ –Ω–∞ RTX 6000 96GB

| –ú–æ–¥–µ–ª—å | VRAM | –ü–∞—Ä–∞–º–µ—Ç—Ä—ã |
|--------|------|-----------|
| Llama-3.1-8B ‚úÖ | 16GB | –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è |
| Llama-3.1-70B | 80GB | –ú–∞–∫—Å –∫–∞—á–µ—Å—Ç–≤–æ |
| Mistral-7B | 14GB | –ë—ã—Å—Ç—Ä–∞—è |
| Mixtral-8x7B | 90GB | –î–ª–∏–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç |

## üìù –ò–∑–º–µ–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏

–û—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π—Ç–µ –≤ `.env.vllm`:
```bash
VLLM_MODEL=mistralai/Mistral-7B-Instruct-v0.2
```

–ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç–µ:
```bash
make down-vllm && make up-vllm
```

## üìö –ü–æ–ª–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

–°–º. [docs/VLLM_DEPLOYMENT.md](docs/VLLM_DEPLOYMENT.md)

