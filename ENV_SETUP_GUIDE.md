# Environment Setup Guide

–†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è `docker-compose.vllm-mig.yml`.

## üéØ –ë—ã—Å—Ç—Ä–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞

Docker Compose –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç —Ñ–∞–π–ª `.env` –∏–∑ –∫–æ—Ä–Ω—è –ø—Ä–æ–µ–∫—Ç–∞. –î–æ–±–∞–≤—å—Ç–µ —Å–ª–µ–¥—É—é—â–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –≤ –≤–∞—à `.env` —Ñ–∞–π–ª:

## üìù –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è .env —Ñ–∞–π–ª–∞

```bash
# ==================================================================
# HuggingFace Token
# ==================================================================
HF_TOKEN=your_huggingface_token_here

# ==================================================================
# MEDIUM Model Configuration (–ø–æ—Ä—Ç 8001)
# ==================================================================
VLLM_MODEL_MEDIUM=OpenGPT/gpt-oss-20b
VLLM_GPU_MEMORY_UTILIZATION_MEDIUM=0.85
VLLM_MAX_MODEL_LEN_MEDIUM=8192
VLLM_MAX_NUM_SEQS_MEDIUM=128

# ==================================================================
# SMALL Model Configuration (–ø–æ—Ä—Ç 8002)
# ==================================================================
VLLM_MODEL_SMALL=mistralai/Mistral-7B-Instruct-v0.3
VLLM_GPU_MEMORY_UTILIZATION_SMALL=0.90
VLLM_MAX_MODEL_LEN_SMALL=16384
VLLM_MAX_NUM_SEQS_SMALL=256

# ==================================================================
# MIG Device IDs
# ==================================================================
MIG_MEDIUM=MIG-GPU-xxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx/7/0
MIG_SMALL=MIG-GPU-xxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx/14/0
MIG_1G_24GB=MIG-GPU-xxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx/15/0

# ==================================================================
# Common Settings
# ==================================================================
VLLM_TENSOR_PARALLEL_SIZE=1
VLLM_ENFORCE_EAGER=false
```

## üöÄ –°–ø–æ—Å–æ–±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### –°–ø–æ—Å–æ–± 1: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ—Å–Ω–æ–≤–Ω–æ–π .env —Ñ–∞–π–ª (–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)

–≠—Ç–æ —Å–∞–º—ã–π –ø—Ä–æ—Å—Ç–æ–π —Å–ø–æ—Å–æ–±. Docker Compose –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≥—Ä—É–∑–∏—Ç `.env`:

```bash
# 1. –î–æ–±–∞–≤—å—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –≤—ã—à–µ –≤ –≤–∞—à .env —Ñ–∞–π–ª
vim .env

# 2. –ü–æ–ª—É—á–∏—Ç–µ MIG UUID
nvidia-smi -L
# –∏–ª–∏
bash scripts/list_mig_devices.sh

# 3. –û–±–Ω–æ–≤–∏—Ç–µ MIG_MEDIUM, MIG_SMALL, MIG_1G_24GB –≤ .env

# 4. –ó–∞–ø—É—Å—Ç–∏—Ç–µ
docker-compose -f docker-compose.vllm-mig.yml up -d
# –∏–ª–∏
make up-vllm-mig
```

### –°–ø–æ—Å–æ–± 2: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ—Ç–¥–µ–ª—å–Ω—ã–π .env —Ñ–∞–π–ª

–ï—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è vLLM –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏:

```bash
# 1. –°–æ–∑–¥–∞–π—Ç–µ –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ñ–∞–π–ª
cp ENV_SETUP_GUIDE.md .env.vllm-mig
vim .env.vllm-mig

# 2. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å —è–≤–Ω—ã–º —É–∫–∞–∑–∞–Ω–∏–µ–º —Ñ–∞–π–ª–∞
docker-compose --env-file .env.vllm-mig -f docker-compose.vllm-mig.yml up -d
```

### –°–ø–æ—Å–æ–± 3: –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –≤ shell

–î–ª—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:

```bash
# –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–π—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
export VLLM_MODEL_MEDIUM=OpenGPT/gpt-oss-20b
export VLLM_MODEL_SMALL=mistralai/Mistral-7B-Instruct-v0.3
export MIG_MEDIUM=MIG-GPU-xxxxx.../7/0
export MIG_SMALL=MIG-GPU-xxxxx.../14/0
export MIG_1G_24GB=MIG-GPU-xxxxx.../15/0

# –ó–∞–ø—É—Å—Ç–∏—Ç–µ
docker-compose -f docker-compose.vllm-mig.yml up -d
```

## üîç –ü–æ–ª—É—á–µ–Ω–∏–µ MIG UUID

### –ú–µ—Ç–æ–¥ 1: nvidia-smi

```bash
nvidia-smi -L
```

–í—ã–≤–æ–¥:
```
GPU 0: NVIDIA RTX 6000 Ada Generation (UUID: GPU-12345678-1234-1234-1234-123456789abc)
  MIG 2g.48gb Device 0: (UUID: MIG-GPU-12345678-1234-1234-1234-123456789abc/7/0)
  MIG 1g.24gb Device 1: (UUID: MIG-GPU-12345678-1234-1234-1234-123456789abc/14/0)
  MIG 1g.24gb Device 2: (UUID: MIG-GPU-12345678-1234-1234-1234-123456789abc/15/0)
```

### –ú–µ—Ç–æ–¥ 2: –°–∫—Ä–∏–ø—Ç

```bash
bash scripts/list_mig_devices.sh
```

### –ú–µ—Ç–æ–¥ 3: nvidia-smi —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π

```bash
nvidia-smi mig -lgi  # List GPU Instances
nvidia-smi mig -lci  # List Compute Instances
```

## ‚öôÔ∏è –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ Makefile

Makefile —É–∂–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω –Ω–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ `.env` —Ñ–∞–π–ª–∞. –ö–æ–º–∞–Ω–¥—ã:

```bash
# –ó–∞–ø—É—Å–∫ (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç .env –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
make up-vllm-mig

# –î–ª—è dual models —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–º .env —Ñ–∞–π–ª–æ–º
make up-dual-models  # –∏—Å–ø–æ–ª—å–∑—É–µ—Ç .env.vllm-dual-models –µ—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç

# –õ–æ–≥–∏
make logs-medium
make logs-small

# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
make test-dual-models
```

## üìã –ü–æ–ª–Ω—ã–π –ø—Ä–∏–º–µ—Ä .env —Ñ–∞–π–ª–∞

```bash
# ==================================================================
# vLLM Dual Models Configuration
# ==================================================================

# HuggingFace Token (–ø–æ–ª—É—á–∏—Ç–µ –Ω–∞ https://huggingface.co/settings/tokens)
HF_TOKEN=hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# ==================================================================
# MEDIUM Model (–±–æ–ª—å—à–∞—è –º–æ–¥–µ–ª—å, 2g.48gb MIG, –ø–æ—Ä—Ç 8001)
# ==================================================================
VLLM_MODEL_MEDIUM=OpenGPT/gpt-oss-20b
VLLM_GPU_MEMORY_UTILIZATION_MEDIUM=0.85
VLLM_MAX_MODEL_LEN_MEDIUM=8192
VLLM_MAX_NUM_SEQS_MEDIUM=128

# ==================================================================
# SMALL Model (–º–µ–Ω—å—à–∞—è –º–æ–¥–µ–ª—å, 1g.24gb MIG, –ø–æ—Ä—Ç 8002)
# ==================================================================
VLLM_MODEL_SMALL=mistralai/Mistral-7B-Instruct-v0.3
VLLM_GPU_MEMORY_UTILIZATION_SMALL=0.90
VLLM_MAX_MODEL_LEN_SMALL=16384
VLLM_MAX_NUM_SEQS_SMALL=256

# ==================================================================
# MIG Devices (–∑–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ –≤–∞—à–∏ UUID)
# ==================================================================
MIG_MEDIUM=MIG-GPU-12345678-1234-1234-1234-123456789abc/7/0
MIG_SMALL=MIG-GPU-12345678-1234-1234-1234-123456789abc/14/0
MIG_1G_24GB=MIG-GPU-12345678-1234-1234-1234-123456789abc/15/0

# ==================================================================
# Common Settings
# ==================================================================
VLLM_TENSOR_PARALLEL_SIZE=1
VLLM_ENFORCE_EAGER=false

# Qdrant
QDRANT_URL=http://qdrant:6333
QDRANT_COLLECTION=docs

# Embeddings
EMBED_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Backend LLM (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç MEDIUM model –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
LLM_MODE=vllm
LLM_VLLM_URL=http://vllm-medium:8001/v1
LLM_TIMEOUT=120
LLM_MAX_TOKENS=512
LLM_TEMPERATURE=0.3

# Document Processing
CHUNK_TOKENS=400
CHUNK_OVERLAP=50

# Search & RAG
CONTEXT_MAX_CHUNKS=6
TOP_K_DEFAULT=6

# Caching
CACHE_ENABLED=true
CACHE_TTL_SECONDS=600
```

## üîÑ –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –º–µ–∂–¥—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è–º–∏

### –î–ª—è —Ä–∞–∑–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏–π

```bash
# Development
cp .env.dev .env
make up-vllm-mig

# Production
cp .env.prod .env
make up-vllm-mig

# Testing
cp .env.test .env
make up-vllm-mig
```

### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å–∏–º–ª–∏–Ω–∫–∞

```bash
# –°–æ–∑–¥–∞—Ç—å —Å–∏–º–ª–∏–Ω–∫ –Ω–∞ —Ç–µ–∫—É—â—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
ln -sf .env.vllm-mig .env

# –ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å—Å—è –Ω–∞ –¥—Ä—É–≥—É—é
rm .env
ln -sf .env.ollama .env
```

## üéØ –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

–ü–æ—Å–ª–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ `.env` —Ñ–∞–π–ª–∞:

```bash
# 1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
cat .env | grep -E "VLLM_MODEL|MIG_"

# 2. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ docker-compose –≤–∏–¥–∏—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
docker-compose -f docker-compose.vllm-mig.yml config | grep VLLM_MODEL

# 3. –ó–∞–ø—É—Å—Ç–∏—Ç–µ
docker-compose -f docker-compose.vllm-mig.yml up -d

# 4. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ health
curl http://localhost:8001/health
curl http://localhost:8002/health

# 5. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –º–æ–¥–µ–ª–∏
curl http://localhost:8001/v1/models
curl http://localhost:8002/v1/models
```

## üìö –ü—Ä–∏–º–µ—Ä—ã –º–æ–¥–µ–ª–µ–π

### –î–ª—è MEDIUM model (2g.48gb, ~40-48 GB)

```bash
# 20B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –æ–±—â–µ–≥–æ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è
VLLM_MODEL_MEDIUM=OpenGPT/gpt-oss-20b

# 13B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –æ—Ç Meta
VLLM_MODEL_MEDIUM=meta-llama/Llama-2-13b-chat-hf

# MoE –º–æ–¥–µ–ª—å, –≤—ã—Å–æ–∫–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
VLLM_MODEL_MEDIUM=mistralai/Mixtral-8x7B-Instruct-v0.1

# 11B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è
VLLM_MODEL_MEDIUM=upstage/SOLAR-10.7B-Instruct-v1.0
```

### –î–ª—è SMALL model (1g.24gb, ~14-20 GB)

```bash
# 7B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, —Ö–æ—Ä–æ—à–æ –¥–ª—è –∫–æ–¥–∞
VLLM_MODEL_SMALL=mistralai/Mistral-7B-Instruct-v0.3

# 7B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –æ—Ç Meta
VLLM_MODEL_SMALL=meta-llama/Llama-2-7b-chat-hf

# 7B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, —Ö–æ—Ä–æ—à–æ —Å–ª–µ–¥—É–µ—Ç –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º
VLLM_MODEL_SMALL=teknium/OpenHermes-2.5-Mistral-7B

# 7B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –ø–æ–¥–¥–µ—Ä–∂–∫–∞ —Ñ—É–Ω–∫—Ü–∏–π
VLLM_MODEL_SMALL=NousResearch/Hermes-2-Pro-Mistral-7B
```

## üêõ Troubleshooting

### –ü—Ä–æ–±–ª–µ–º–∞: Docker Compose –Ω–µ –∑–∞–≥—Ä—É–∂–∞–µ—Ç .env

**–†–µ—à–µ–Ω–∏–µ:**
```bash
# –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ .env –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞
ls -la .env

# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞
chmod 644 .env

# –Ø–≤–Ω–æ —É–∫–∞–∂–∏—Ç–µ —Ñ–∞–π–ª
docker-compose --env-file .env -f docker-compose.vllm-mig.yml up -d
```

### –ü—Ä–æ–±–ª–µ–º–∞: MIG —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã

**–†–µ—à–µ–Ω–∏–µ:**
```bash
# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ MIG
nvidia-smi -L

# –ù–∞—Å—Ç—Ä–æ–π—Ç–µ MIG –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
sudo bash scripts/setup_mig.sh

# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ device_ids –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å
docker run --rm --gpus device=${MIG_MEDIUM} nvidia/cuda:12.0-base nvidia-smi
```

### –ü—Ä–æ–±–ª–µ–º–∞: –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –Ω–µ –ø–æ–¥—Å—Ç–∞–≤–ª—è—é—Ç—Å—è

**–†–µ—à–µ–Ω–∏–µ:**
```bash
# –£–±–µ–¥–∏—Ç–µ—Å—å –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ (–±–µ–∑ –ø—Ä–æ–±–µ–ª–æ–≤ –≤–æ–∫—Ä—É–≥ =)
# –ü—Ä–∞–≤–∏–ª—å–Ω–æ:
VLLM_MODEL_MEDIUM=OpenGPT/gpt-oss-20b

# –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ:
VLLM_MODEL_MEDIUM = OpenGPT/gpt-oss-20b

# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —á—Ç–æ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä—É—é—Ç—Å—è
docker-compose -f docker-compose.vllm-mig.yml config
```

## üí° –°–æ–≤–µ—Ç—ã

1. **–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –æ—Å–Ω–æ–≤–Ω–æ–π .env —Ñ–∞–π–ª** - Docker Compose –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –µ–≥–æ –∑–∞–≥—Ä—É–∂–∞–µ—Ç
2. **–•—Ä–∞–Ω–∏—Ç–µ —à–∞–±–ª–æ–Ω** - —Å–æ–∑–¥–∞–π—Ç–µ `.env.template` –¥–ª—è –∫–æ–º–∞–Ω–¥—ã
3. **–ù–µ –∫–æ–º–º–∏—Ç—å—Ç–µ .env** - —É–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ –æ–Ω –≤ `.gitignore`
4. **–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏** - –¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ –∫–∞–∂–¥—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
5. **–ì—Ä—É–ø–ø–∏—Ä—É–π—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ** - –ø–æ —Å–µ—Ä–≤–∏—Å–∞–º –∏–ª–∏ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏

## üìñ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

- [Docker Compose Environment Variables](https://docs.docker.com/compose/environment-variables/)
- [NVIDIA MIG User Guide](https://docs.nvidia.com/datacenter/tesla/mig-user-guide/)
- [vLLM Environment Variables](https://docs.vllm.ai/en/latest/serving/env_vars.html)

