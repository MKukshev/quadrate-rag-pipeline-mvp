# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –æ–∫–Ω–∞: Ollama vs vLLM

## üìã –ß—Ç–æ –±—ã–ª–æ —Å–¥–µ–ª–∞–Ω–æ

### –ü—Ä–æ–±–ª–µ–º–∞
–î–ª—è vLLM –±—ã–ª –ø–∞—Ä–∞–º–µ—Ç—Ä `VLLM_MAX_MODEL_LEN`, –æ–ø—Ä–µ–¥–µ–ª—è—é—â–∏–π —Ä–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –æ–∫–Ω–∞, –Ω–æ –¥–ª—è Ollama –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ –Ω–µ –±—ã–ª–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ.

### –†–µ—à–µ–Ω–∏–µ
–î–æ–±–∞–≤–ª–µ–Ω –ø–∞—Ä–∞–º–µ—Ç—Ä **`OLLAMA_NUM_CTX`** - –∞–Ω–∞–ª–æ–≥ `VLLM_MAX_MODEL_LEN` –¥–ª—è Ollama.

---

## üîß –ò–∑–º–µ–Ω–µ–Ω–∏—è –≤ –∫–æ–¥–µ

### 1. `backend/services/config.py`

–î–æ–±–∞–≤–ª–µ–Ω–∞ –Ω–æ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è:

```python
OLLAMA_NUM_CTX = int(os.getenv("OLLAMA_NUM_CTX", "40960"))  # Context window for Ollama
```

### 2. `backend/services/rag.py`

–î–æ–±–∞–≤–ª–µ–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ `OLLAMA_NUM_CTX` –≤ API –∑–∞–ø—Ä–æ—Å–∞—Ö –∫ Ollama:

```python
# –ò–º–ø–æ—Ä—Ç
from .config import (
    ...
    OLLAMA_NUM_CTX,
)

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ call_llm()
r = requests.post(
    "http://ollama:11434/api/generate",
    json={
        "model": LLM_MODEL,
        "prompt": prompt,
        "stream": LLM_STREAM_ENABLED,
        "options": {
            "num_predict": LLM_MAX_TOKENS,
            "num_ctx": OLLAMA_NUM_CTX,  # ‚Üê NEW
        },
    },
    ...
)
```

### 3. `docker-compose.yml`

–î–æ–±–∞–≤–ª–µ–Ω–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è backend –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞:

```yaml
environment:
  - LLM_MODE=ollama
  - LLM_MODEL=${LLM_MODEL:-qwen3:14b}
  - OLLAMA_NUM_CTX=${OLLAMA_NUM_CTX:-40960}  # ‚Üê NEW
  ...
```

### 4. `.env.ollama.new`

–î–æ–±–∞–≤–ª–µ–Ω –ø–∞—Ä–∞–º–µ—Ç—Ä –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ñ–∞–π–ª:

```bash
OLLAMA_NUM_CTX=40960
```

---

## üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

### vLLM (docker-compose.vllm-mig.yml)

```yaml
vllm-medium:
  environment:
    - VLLM_MODEL=${VLLM_MODEL_MEDIUM:-OpenGPT/gpt-oss-20b}
    - VLLM_MAX_MODEL_LEN=${VLLM_MAX_MODEL_LEN_MEDIUM:-8192}  # ‚Üê Context window
```

**–ì–¥–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è:**
- –ü–µ—Ä–µ–¥–∞–µ—Ç—Å—è –≤ vLLM —Å–µ—Ä–≤–µ—Ä –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ
- `--max-model-len ${VLLM_MAX_MODEL_LEN}`

### Ollama (docker-compose.yml)

```yaml
backend:
  environment:
    - LLM_MODE=ollama
    - LLM_MODEL=${LLM_MODEL:-qwen3:14b}
    - OLLAMA_NUM_CTX=${OLLAMA_NUM_CTX:-40960}  # ‚Üê Context window
```

**–ì–¥–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è:**
- –ü–µ—Ä–µ–¥–∞–µ—Ç—Å—è –≤ Ollama API –ø—Ä–∏ –∫–∞–∂–¥–æ–º –≤—ã–∑–æ–≤–µ
- `options: { "num_ctx": OLLAMA_NUM_CTX }`

---

## üéØ –î–≤–∞ —Ä–∞–∑–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–∞!

### –í–ê–ñ–ù–û: Context Window ‚â† Summarization Threshold

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –ì–¥–µ | –ó–Ω–∞—á–µ–Ω–∏–µ | –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ |
|----------|-----|----------|------------|
| **OLLAMA_NUM_CTX** | `.env` + `docker-compose.yml` | 40960 | –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –æ–∫–Ω–∞ –º–æ–¥–µ–ª–∏ |
| **summarization_threshold** | `config/llm_models.json` | 15000 | –ü–æ—Ä–æ–≥ –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è –∞–≤—Ç–æ-—Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ |

### –ü–æ—á–µ–º—É threshold –º–µ–Ω—å—à–µ?

```
OLLAMA_NUM_CTX = 40960 —Ç–æ–∫–µ–Ω–æ–≤ (100%)
‚îú‚îÄ system_prompt: ~500 —Ç–æ–∫–µ–Ω–æ–≤
‚îú‚îÄ max_output_tokens: 2048 —Ç–æ–∫–µ–Ω–æ–≤  
‚îú‚îÄ safety margin: ~500 —Ç–æ–∫–µ–Ω–æ–≤
‚îî‚îÄ effective_context: ~38000 —Ç–æ–∫–µ–Ω–æ–≤ (93%)

summarization_threshold = 15000 —Ç–æ–∫–µ–Ω–æ–≤ (~37% –æ—Ç context_window)
```

**–ü—Ä–∏—á–∏–Ω–∞:**
- –°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –≤–∫–ª—é—á–∞–µ—Ç—Å—è —Ä–∞–Ω—å—à–µ, —á–µ–º –∑–∞–ø–æ–ª–Ω—è–µ—Ç—Å—è –≤–µ—Å—å –∫–æ–Ω—Ç–µ–∫—Å—Ç
- –û—Å—Ç–∞–≤–ª—è–µ—Ç –∑–∞–ø–∞—Å –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞, –≤—ã–≤–æ–¥–∞ –∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
- –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç —Å–∫–æ—Ä–æ—Å—Ç—å –∏ –∫–∞—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–æ–≤

---

## üîç –î–ª—è qwen3:14b

### –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏ (–∏–∑ Ollama API)

```json
{
  "qwen3.context_length": 40960,
  "parameter_size": "14.8B",
  "quantization": "Q4_K_M"
}
```

### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≤ llm_models.json

```json
{
  "model_name": "qwen3:14b",
  "provider": "ollama",
  "context_window": 40960,          // ‚Üê –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç OLLAMA_NUM_CTX
  "max_output_tokens": 2048,
  "summarization_threshold": 15000,  // ‚Üê 37% –æ—Ç context_window
  "summarization_max_output": 5000
}
```

### –í .env —Ñ–∞–π–ª–µ

```bash
# Context window –¥–ª—è –º–æ–¥–µ–ª–∏
OLLAMA_NUM_CTX=40960

# –í—ã—Ö–æ–¥ –º–æ–¥–µ–ª–∏ –∑–∞ –æ–¥–∏–Ω –∑–∞–ø—Ä–æ—Å
LLM_MAX_TOKENS=2048
```

---

## üéØ –í–∞–∂–Ω–æ: –ï–¥–∏–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏!

### –î–ª—è –û–ë–ï–ò–• –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π (Ollama –∏ vLLM)

–ü–æ—Ä–æ–≥ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ (`summarization_threshold`) **–í–°–ï–ì–î–ê** –±–µ—Ä—ë—Ç—Å—è –∏–∑ `config/llm_models.json`.

**–ö–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç:**

1. Backend —á–∏—Ç–∞–µ—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è:
   - `LLM_MODE` (ollama/vllm)
   - `LLM_MODEL` (qwen3:14b / openai/gpt-oss-20b)

2. –§—É–Ω–∫—Ü–∏—è `get_current_model_config()` –∏—â–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –≤ `llm_models.json`

3. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç `summarization_threshold` –∏–∑ –Ω–∞–π–¥–µ–Ω–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

**–ü—Ä–∏–º–µ—Ä –¥–ª—è Ollama:**
```bash
# .env
LLM_MODE=ollama
LLM_MODEL=qwen3:14b

# ‚Üí –ò—â–µ—Ç –≤ llm_models.json:
{
  "model_name": "qwen3:14b",
  "provider": "ollama",
  "summarization_threshold": 15000  # ‚Üê –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —ç—Ç–æ –∑–Ω–∞—á–µ–Ω–∏–µ
}
```

**–ü—Ä–∏–º–µ—Ä –¥–ª—è vLLM:**
```bash
# .env
LLM_MODE=vllm
LLM_MODEL=openai/gpt-oss-20b

# ‚Üí –ò—â–µ—Ç –≤ llm_models.json:
{
  "model_name": "openai/gpt-oss-20b",
  "provider": "vllm",
  "summarization_threshold": 3000  # ‚Üê –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —ç—Ç–æ –∑–Ω–∞—á–µ–Ω–∏–µ
}
```

### –ì–¥–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–æ—Ä–æ–≥ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏?

**–í –∫–æ–¥–µ backend/app.py:**

```python
# –°—Ç—Ä–æ–∫–∞ 256
model_config = get_current_model_config()  # –ß–∏—Ç–∞–µ—Ç –∏–∑ llm_models.json

# –°—Ç—Ä–æ–∫–∞ 276 (—Ä–µ–∂–∏–º "auto")
should_summarize = context_tokens > model_config.summarization_threshold

# –ï—Å–ª–∏ context_tokens > threshold ‚Üí –≤–∫–ª—é—á–∞–µ—Ç—Å—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è
```

### VLLM_MAX_MODEL_LEN vs summarization_threshold

**–î–≤–∞ —Ä–∞–∑–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–∞!**

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –ì–¥–µ | –î–ª—è —á–µ–≥–æ |
|----------|-----|----------|
| `VLLM_MAX_MODEL_LEN` | .env ‚Üí vLLM server | –†–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –æ–∫–Ω–∞ —Å–µ—Ä–≤–µ—Ä–∞ vLLM |
| `summarization_threshold` | llm_models.json | –ü–æ—Ä–æ–≥ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –≤ RAG |

**–ê–Ω–∞–ª–æ–≥–∏—è –¥–ª—è Ollama:**

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –ì–¥–µ | –î–ª—è —á–µ–≥–æ |
|----------|-----|----------|
| `OLLAMA_NUM_CTX` | .env ‚Üí Ollama API | –†–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –æ–∫–Ω–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ Ollama |
| `summarization_threshold` | llm_models.json | –ü–æ—Ä–æ–≥ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –≤ RAG |

---

## ‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

### 1. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ –ø–∞—Ä–∞–º–µ—Ç—Ä —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω

```bash
# –í –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ backend
docker compose exec backend env | grep OLLAMA_NUM_CTX
# –î–æ–ª–∂–Ω–æ –ø–æ–∫–∞–∑–∞—Ç—å: OLLAMA_NUM_CTX=40960
```

### 2. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –≤ –ª–æ–≥–∞—Ö Ollama

```bash
# –ü–æ—Å–ª–µ –≤—ã–∑–æ–≤–∞ LLM —É–≤–∏–¥–∏—Ç–µ –≤ –ª–æ–≥–∞—Ö
curl -X POST http://localhost:8000/ask -d '{"q":"test","space_id":"demo"}'

# –í –ª–æ–≥–∞—Ö Ollama –±—É–¥–µ—Ç –≤–∏–¥–Ω–æ:
# "num_ctx": 40960
```

### 3. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –º–æ–¥–µ–ª–∏

```bash
curl http://localhost:8000/model-config | jq
```

**–û–∂–∏–¥–∞–µ–º—ã–π –æ—Ç–≤–µ—Ç:**

```json
{
  "model_name": "qwen3:14b",
  "context_window": 40960,
  "summarization_threshold": 15000,
  "effective_context_for_rag": 38912
}
```

---

## üöÄ –ì–æ—Ç–æ–≤–æ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!

–¢–µ–ø–µ—Ä—å:
- ‚úÖ Ollama –∏–º–µ–µ—Ç —è–≤–Ω–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω–æ–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–µ –æ–∫–Ω–æ (40960)
- ‚úÖ –ê–Ω–∞–ª–æ–≥–∏—á–Ω–æ vLLM (VLLM_MAX_MODEL_LEN)
- ‚úÖ –ü–æ—Ä–æ–≥ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ (15000)
- ‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–æ–≤–º–µ—Å—Ç–∏–º–∞ —Å vLLM MIG setup
- ‚úÖ –ì–æ—Ç–æ–≤–æ –∫ –æ—Ç–ª–∞–¥–∫–µ 6 –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏!

**–°–ª–µ–¥—É—é—â–∏–π —à–∞–≥:** –ó–∞–ø—É—Å—Ç–∏—Ç—å –∏ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å! üéØ

