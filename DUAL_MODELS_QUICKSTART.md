# Dual vLLM Models Configuration Guide

–†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–º—É –∑–∞–ø—É—Å–∫—É –¥–≤—É—Ö –º–æ–¥–µ–ª–µ–π vLLM —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º NVIDIA MIG.

## üìã –û–±–∑–æ—Ä –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      NVIDIA GPU (96GB)                       ‚îÇ
‚îÇ                     MIG Partitioning                         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  2g.48gb MIG    ‚îÇ  1g.24gb MIG    ‚îÇ    1g.24gb MIG          ‚îÇ
‚îÇ  (MEDIUM model) ‚îÇ  (SMALL model)  ‚îÇ    (Backend/Embed)      ‚îÇ
‚îÇ  Port: 8001     ‚îÇ  Port: 8002     ‚îÇ    Port: 8000           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                 ‚îÇ                      ‚îÇ
         ‚îÇ                 ‚îÇ                      ‚îÇ
    http://localhost:8001/v1  http://localhost:8002/v1
         ‚îÇ                 ‚îÇ                      ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
                    AnythingLLM / Applications
```

## üöÄ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ MIG —É—Å—Ç—Ä–æ–π—Å—Ç–≤

–ü–æ–ª—É—á–∏—Ç–µ —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö MIG —É—Å—Ç—Ä–æ–π—Å—Ç–≤:

```bash
nvidia-smi -L
# –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –Ω–∞—à —Å–∫—Ä–∏–ø—Ç
bash scripts/list_mig_devices.sh
```

–ü—Ä–∏–º–µ—Ä –≤—ã–≤–æ–¥–∞:
```
GPU 0: NVIDIA RTX 6000 Ada Generation
  MIG 2g.48gb Device 0: (UUID: MIG-GPU-xxxxx.../7/0)
  MIG 1g.24gb Device 1: (UUID: MIG-GPU-xxxxx.../14/0)
  MIG 1g.24gb Device 2: (UUID: MIG-GPU-xxxxx.../15/0)
```

### 2. –°–æ–∑–¥–∞–Ω–∏–µ .env —Ñ–∞–π–ª–∞

–°–æ–∑–¥–∞–π—Ç–µ –∏–ª–∏ –æ–±–Ω–æ–≤–∏—Ç–µ —Ñ–∞–π–ª `.env` –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞ —Å –≤–∞—à–∏–º–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏:

> üí° **–°–æ–≤–µ—Ç**: Docker Compose –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç `.env` —Ñ–∞–π–ª. –°–º. –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ –≤ `ENV_SETUP_GUIDE.md`

```bash
# ==================================================================
# HuggingFace Token
# ==================================================================
HF_TOKEN=your_huggingface_token_here

# ==================================================================
# MEDIUM Model Configuration (–±–æ–ª—å—à–∞—è –º–æ–¥–µ–ª—å, –ø–æ—Ä—Ç 8001)
# –ü—Ä–∏–º–µ—Ä: OpenGPT/gpt-oss-20b, meta-llama/Llama-2-13b-chat-hf
# ==================================================================
VLLM_MODEL_MEDIUM=OpenGPT/gpt-oss-20b
VLLM_GPU_MEMORY_UTILIZATION_MEDIUM=0.85
VLLM_MAX_MODEL_LEN_MEDIUM=8192
VLLM_MAX_NUM_SEQS_MEDIUM=128

# ==================================================================
# SMALL Model Configuration (–º–µ–Ω—å—à–∞—è –º–æ–¥–µ–ª—å, –ø–æ—Ä—Ç 8002)
# –ü—Ä–∏–º–µ—Ä: mistralai/Mistral-7B-Instruct-v0.3, meta-llama/Llama-2-7b-chat-hf
# ==================================================================
VLLM_MODEL_SMALL=mistralai/Mistral-7B-Instruct-v0.3
VLLM_GPU_MEMORY_UTILIZATION_SMALL=0.90
VLLM_MAX_MODEL_LEN_SMALL=16384
VLLM_MAX_NUM_SEQS_SMALL=256

# ==================================================================
# MIG Device IDs
# ==================================================================
# MEDIUM model –Ω–∞ 2g.48gb –∏–Ω—Å—Ç–∞–Ω—Å–µ
MIG_MEDIUM=MIG-GPU-xxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx/7/0

# SMALL model –Ω–∞ 1g.24gb –∏–Ω—Å—Ç–∞–Ω—Å–µ
MIG_SMALL=MIG-GPU-xxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx/14/0

# Backend embeddings –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω–æ–º 1g.24gb –∏–Ω—Å—Ç–∞–Ω—Å–µ
MIG_1G_24GB=MIG-GPU-xxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx/15/0
```

### 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

```bash
# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
make check-env
```

### 4. –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–∏—Å–æ–≤

```bash
# –ó–∞–ø—É—Å–∫ (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç .env —Ñ–∞–π–ª –∏–∑ –∫–æ—Ä–Ω—è –ø—Ä–æ–µ–∫—Ç–∞)
make up-dual-models

# –ò–ª–∏ –Ω–∞–ø—Ä—è–º—É—é —á–µ—Ä–µ–∑ docker-compose
docker-compose -f docker-compose.vllm-mig.yml up -d
```

> üí° **–í–∞–∂–Ω–æ**: –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ `.env` —Ñ–∞–π–ª –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞. Docker Compose –∑–∞–≥—Ä—É–∑–∏—Ç –µ–≥–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏.

### 5. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏

```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ MEDIUM model (–ø–æ—Ä—Ç 8001)
curl http://localhost:8001/health
curl http://localhost:8001/v1/models

# –ü—Ä–æ–≤–µ—Ä–∫–∞ SMALL model (–ø–æ—Ä—Ç 8002)
curl http://localhost:8002/health
curl http://localhost:8002/v1/models

# –ü—Ä–æ–≤–µ—Ä–∫–∞ Qdrant
curl http://localhost:6333/healthz

# –ü—Ä–æ–≤–µ—Ä–∫–∞ Backend
curl http://localhost:8000/health
```

## üîß –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è AnythingLLM

### –í–∞—Ä–∏–∞–Ω—Ç 1: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å MEDIUM model (–º–æ—â–Ω–µ–µ, –º–µ–¥–ª–µ–Ω–Ω–µ–µ)

```
LLM Provider: Generic OpenAI
Base URL: http://localhost:8001/v1
API Key: not-needed
Model Name: <your-medium-model-name>
```

–ü—Ä–∏–º–µ—Ä—ã: `OpenGPT/gpt-oss-20b`, `meta-llama/Llama-2-13b-chat-hf`

### –í–∞—Ä–∏–∞–Ω—Ç 2: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å SMALL model (–±—ã—Å—Ç—Ä–µ–µ, —ç–∫–æ–Ω–æ–º–∏—á–Ω–µ–µ)

```
LLM Provider: Generic OpenAI
Base URL: http://localhost:8002/v1
API Key: not-needed
Model Name: <your-small-model-name>
```

–ü—Ä–∏–º–µ—Ä—ã: `mistralai/Mistral-7B-Instruct-v0.3`, `meta-llama/Llama-2-7b-chat-hf`

### –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏

AnythingLLM –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ –∏ –ø–µ—Ä–µ–∫–ª—é—á–∞—Ç—å—Å—è –º–µ–∂–¥—É –Ω–∏–º–∏:

1. –î–æ–±–∞–≤—å—Ç–µ –æ–±–∞ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö
2. –î–∞–π—Ç–µ –∏–º —Ä–∞–∑–Ω—ã–µ –∏–º–µ–Ω–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "Medium Model" –∏ "Small Model")
3. –ü–µ—Ä–µ–∫–ª—é—á–∞–π—Ç–µ—Å—å –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∑–∞–¥–∞—á–∏

## üìä –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π

### –¢–µ—Å—Ç MEDIUM model

```bash
curl -X POST http://localhost:8001/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "<your-medium-model-name>",
    "messages": [
      {"role": "system", "content": "You are a helpful assistant."},
      {"role": "user", "content": "Explain quantum computing in simple terms."}
    ],
    "temperature": 0.7,
    "max_tokens": 200
  }'
```

### –¢–µ—Å—Ç SMALL model

```bash
curl -X POST http://localhost:8002/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "<your-small-model-name>",
    "messages": [
      {"role": "user", "content": "Write a Python function to calculate fibonacci numbers."}
    ],
    "temperature": 0.7,
    "max_tokens": 200
  }'
```

## üéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é

### MEDIUM model (–ø–æ—Ä—Ç 8001)
- ‚úÖ –õ—É—á—à–µ –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π
- ‚úÖ –õ—É—á—à–µ –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤
- ‚úÖ –ë–æ–ª–µ–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
- ‚ùå –ú–µ–¥–ª–µ–Ω–Ω–µ–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
- ‚ùå –¢—Ä–µ–±—É–µ—Ç –±–æ–ª—å—à–µ –ø–∞–º—è—Ç–∏

**–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è:**
- –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á
- –†–∞–±–æ—Ç—ã —Å –±–æ–ª—å—à–∏–º–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏
- –°–ª–æ–∂–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π

### SMALL model (–ø–æ—Ä—Ç 8002)
- ‚úÖ –ë—ã—Å—Ç—Ä–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
- ‚úÖ –ú–µ–Ω—å—à–µ –ø–∞–º—è—Ç–∏
- ‚úÖ –•–æ—Ä–æ—à–æ –¥–ª—è –∫–æ–¥–∞ –∏ –ø—Ä–æ—Å—Ç—ã—Ö –∑–∞–¥–∞—á
- ‚ùå –ú–µ–Ω–µ–µ –¥–µ—Ç–∞–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –Ω–∞ —Å–ª–æ–∂–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã

**–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è:**
- –ë—ã—Å—Ç—Ä—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
- –ì–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–¥–∞
- –ü—Ä–æ—Å—Ç—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤
- –í—ã—Å–æ–∫–æ–π –ø—Ä–æ–ø—É—Å–∫–Ω–æ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏

## üîç –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

### –ü—Ä–æ—Å–º–æ—Ç—Ä –ª–æ–≥–æ–≤

```bash
# –í—Å–µ —Å–µ—Ä–≤–∏—Å—ã
docker-compose -f docker-compose.vllm-mig.yml logs -f

# –¢–æ–ª—å–∫–æ MEDIUM model
docker logs -f vllm-medium

# –¢–æ–ª—å–∫–æ SMALL model
docker logs -f vllm-small

# –ò—Å–ø–æ–ª—å–∑—É—è Make
make logs-medium
make logs-small
make logs-dual-models  # –æ–±–∞ —Å—Ä–∞–∑—É
```

### –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ GPU

```bash
# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ –≤—Å–µ—Ö MIG —É—Å—Ç—Ä–æ–π—Å—Ç–≤
nvidia-smi

# –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ MIG
nvidia-smi mig -lgi
nvidia-smi mig -lci

# Watch —Ä–µ–∂–∏–º
watch -n 1 nvidia-smi
```

## ‚öôÔ∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞—Å—Ç—Ä–æ–π–∫–∏

### GPU Memory Utilization

```bash
# MEDIUM model (–æ–±—ã—á–Ω–æ –±–æ–ª—å—à–∞—è –º–æ–¥–µ–ª—å ~20B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤)
VLLM_GPU_MEMORY_UTILIZATION_MEDIUM=0.85  # 85% –æ—Ç 48GB = ~40GB

# SMALL model (–æ–±—ã—á–Ω–æ –º–µ–Ω—å—à–∞—è –º–æ–¥–µ–ª—å ~7B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤)
VLLM_GPU_MEMORY_UTILIZATION_SMALL=0.90  # 90% –æ—Ç 24GB = ~21GB
```

### Max Model Length (–∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–µ –æ–∫–Ω–æ)

```bash
# MEDIUM model
VLLM_MAX_MODEL_LEN_MEDIUM=8192  # 8K —Ç–æ–∫–µ–Ω–æ–≤ (–Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç—Å—è –ø–æ –º–æ–¥–µ–ª–∏)

# SMALL model
VLLM_MAX_MODEL_LEN_SMALL=16384  # 16K —Ç–æ–∫–µ–Ω–æ–≤ (–Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –º–æ–¥–µ–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç –±–æ–ª—å—à–µ)
```

### Max Num Sequences (batch size)

```bash
# MEDIUM model (–º–µ–Ω—å—à–µ –∏–∑-–∑–∞ —Ä–∞–∑–º–µ—Ä–∞ –º–æ–¥–µ–ª–∏)
VLLM_MAX_NUM_SEQS_MEDIUM=128

# SMALL model (–±–æ–ª—å—à–µ, —Ç.–∫. –º–æ–¥–µ–ª—å –º–µ–Ω—å—à–µ)
VLLM_MAX_NUM_SEQS_SMALL=256
```

## üêõ Troubleshooting

### –ü—Ä–æ–±–ª–µ–º–∞: Out of Memory (OOM)

**–†–µ—à–µ–Ω–∏–µ:**
1. –£–º–µ–Ω—å—à–∏—Ç–µ `VLLM_GPU_MEMORY_UTILIZATION`
2. –£–º–µ–Ω—å—à–∏—Ç–µ `VLLM_MAX_MODEL_LEN`
3. –£–º–µ–Ω—å—à–∏—Ç–µ `VLLM_MAX_NUM_SEQS`

```bash
# –î–ª—è MEDIUM model
VLLM_GPU_MEMORY_UTILIZATION_MEDIUM=0.80  # –±—ã–ª–æ 0.85
VLLM_MAX_MODEL_LEN_MEDIUM=4096          # –±—ã–ª–æ 8192

# –î–ª—è SMALL model
VLLM_GPU_MEMORY_UTILIZATION_SMALL=0.85  # –±—ã–ª–æ 0.90
```

### –ü—Ä–æ–±–ª–µ–º–∞: –ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è

**–ü—Ä–æ–≤–µ—Ä—å—Ç–µ:**
1. –ü—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å MIG UUID –≤ `.env` —Ñ–∞–π–ª–µ
2. –î–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å HuggingFace —Ç–æ–∫–µ–Ω–∞
3. –ù–∞–ª–∏—á–∏–µ –º–µ—Å—Ç–∞ –Ω–∞ –¥–∏—Å–∫–µ –¥–ª—è –∫—ç—à–∞ –º–æ–¥–µ–ª–µ–π

```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ MIG —É—Å—Ç—Ä–æ–π—Å—Ç–≤
nvidia-smi -L

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–æ–≥–æ–≤
docker logs vllm-medium
docker logs vllm-small

# –ò—Å–ø–æ–ª—å–∑—É—è Make
make logs-medium
make logs-small
```

### –ü—Ä–æ–±–ª–µ–º–∞: –ú–µ–¥–ª–µ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è

**–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è:**
1. –£–≤–µ–ª–∏—á—å—Ç–µ `VLLM_MAX_NUM_SEQS` (–µ—Å–ª–∏ –µ—Å—Ç—å –ø–∞–º—è—Ç—å)
2. –í–∫–ª—é—á–∏—Ç–µ `VLLM_ENABLE_CHUNKED_PREFILL=true`
3. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–µ–Ω—å—à—É—é –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –∑–∞–¥–∞—á

## üìà –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

### –ü—Ä–∏–º–µ—Ä–Ω—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏

| –ú–æ–¥–µ–ª—å | Tokens/sec | Latency (first token) | Memory Usage |
|--------|------------|----------------------|--------------|
| MEDIUM (~20B) | ~30-50 | ~500-800ms | ~40-45 GB |
| SMALL (~7B) | ~80-120 | ~200-400ms | ~14-16 GB |

*–ó–∞–≤–∏—Å–∏—Ç –æ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏, –¥–ª–∏–Ω—ã –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

## üîÑ –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–µ—Ä–≤–∏—Å–∞–º–∏

```bash
# –ó–∞–ø—É—Å–∫
docker-compose -f docker-compose.vllm-mig.yml up -d

# –û—Å—Ç–∞–Ω–æ–≤–∫–∞
docker-compose -f docker-compose.vllm-mig.yml down

# –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å–µ—Ä–≤–∏—Å–∞
docker-compose -f docker-compose.vllm-mig.yml restart vllm-medium
docker-compose -f docker-compose.vllm-mig.yml restart vllm-small

# –ò—Å–ø–æ–ª—å–∑—É—è Make
make restart-medium
make restart-small

# –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–æ—Å–ª–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
docker-compose -f docker-compose.vllm-mig.yml up -d --force-recreate
```

## üìö –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

- [vLLM Documentation](https://docs.vllm.ai/)
- [NVIDIA MIG User Guide](https://docs.nvidia.com/datacenter/tesla/mig-user-guide/)
- [HuggingFace Models](https://huggingface.co/models)

## ‚ùì FAQ

**Q: –ú–æ–∂–Ω–æ –ª–∏ –∑–∞–ø—É—Å—Ç–∏—Ç—å –±–æ–ª—å—à–µ –¥–≤—É—Ö –º–æ–¥–µ–ª–µ–π?**
A: –î–∞, –¥–æ–±–∞–≤—å—Ç–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Å–µ—Ä–≤–∏—Å—ã –≤ `docker-compose.vllm-mig.yml` —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏ –ø–æ—Ä—Ç–∞–º–∏ –∏ MIG —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞–º–∏.

**Q: –ö–∞–∫–∏–µ –º–æ–¥–µ–ª–∏ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å?**
A: –õ—é–±—ã–µ –º–æ–¥–µ–ª–∏ –∏–∑ HuggingFace, —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ —Å vLLM. –ü—Ä–∏–º–µ—Ä—ã:
- MEDIUM: OpenGPT/gpt-oss-20b, meta-llama/Llama-2-13b-chat-hf, mistralai/Mixtral-8x7B-Instruct-v0.1
- SMALL: mistralai/Mistral-7B-Instruct-v0.3, meta-llama/Llama-2-7b-chat-hf, teknium/OpenHermes-2.5-Mistral-7B

**Q: –ú–æ–∂–Ω–æ –ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–¥–Ω–æ MIG —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –¥–≤—É—Ö –º–æ–¥–µ–ª–µ–π?**
A: –ù–µ—Ç, –∫–∞–∂–¥–∞—è –º–æ–¥–µ–ª—å –¥–æ–ª–∂–Ω–∞ –∏–º–µ—Ç—å —Å–≤–æ–π –≤—ã–¥–µ–ª–µ–Ω–Ω—ã–π MIG –∏–Ω—Å—Ç–∞–Ω—Å.

**Q: –ö–∞–∫ –∏–∑–º–µ–Ω–∏—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ –ª–µ—Ç—É?**
A: –û–±–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é `VLLM_MODEL_MEDIUM` –∏–ª–∏ `VLLM_MODEL_SMALL` –≤ `.env` —Ñ–∞–π–ª–µ –∏ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–π—Ç–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä:
```bash
docker-compose -f docker-compose.vllm-mig.yml up -d --force-recreate vllm-medium
# –∏–ª–∏
make restart-medium
```

