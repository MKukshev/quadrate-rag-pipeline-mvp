# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Ollama —Å Qwen3:14b –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏

## ‚úÖ –ß—Ç–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ

### 1. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –≤ `config/llm_models.json`

–î–æ–±–∞–≤–ª–µ–Ω–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è `qwen3:14b`:

```json
{
  "model_name": "qwen3:14b",
  "provider": "ollama",
  "context_window": 40960,
  "max_output_tokens": 2048,
  "summarization_threshold": 15000,
  "summarization_max_output": 5000,
  "tokens_per_second": 45,
  "supports_streaming": true,
  "supports_function_calling": true
}
```

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏:**
- ‚úÖ **context_window**: 40960 —Ç–æ–∫–µ–Ω–æ–≤ (–æ—á–µ–Ω—å –±–æ–ª—å—à–æ–µ –æ–∫–Ω–æ!)
- ‚úÖ **summarization_threshold**: 15000 —Ç–æ–∫–µ–Ω–æ–≤
  - –ü—Ä–∏ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–∏ 15K —Ç–æ–∫–µ–Ω–æ–≤ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤–∫–ª—é—á–∞–µ—Ç—Å—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è
- ‚úÖ **summarization_max_output**: 5000 —Ç–æ–∫–µ–Ω–æ–≤ –º–∞–∫—Å–∏–º—É–º –≤ summary

### 2. –û–±–Ω–æ–≤–ª–µ–Ω `docker-compose.yml`

–ú–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑–º–µ–Ω–µ–Ω–∞ –Ω–∞ `qwen3:14b`:

```yaml
- LLM_MODEL=${LLM_MODEL:-qwen3:14b}
```

### 3. –°–æ–∑–¥–∞–Ω `.env` —Ñ–∞–π–ª –¥–ª—è –∑–∞–ø—É—Å–∫–∞

–°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é:

```bash
cp .env.ollama.new .env
```

–ò–ª–∏ —Å–æ–∑–¥–∞—Ç—å –≤—Ä—É—á–Ω—É—é `.env`:

```bash
# Configuration for Ollama with Qwen3:14b
LLM_MODE=ollama
LLM_MODEL=qwen3:14b
LLM_TIMEOUT=240
LLM_MAX_TOKENS=2048
LLM_TEMPERATURE=0.7

# IMPORTANT: Context window size (–∞–Ω–∞–ª–æ–≥ VLLM_MAX_MODEL_LEN –¥–ª—è vLLM)
OLLAMA_NUM_CTX=40960

QDRANT_URL=http://qdrant:6333
QDRANT_COLLECTION=docs
EMBED_MODEL=sentence-transformers/all-MiniLM-L6-v2
KEYWORD_INDEX_DIR=/data/whoosh_index

CHUNK_TOKENS=500
CHUNK_OVERLAP=50
CONTEXT_MAX_CHUNKS=6
TOP_K_DEFAULT=6

CACHE_ENABLED=true
CACHE_TTL_SECONDS=300
```

## üöÄ –ó–∞–ø—É—Å–∫

```bash
# 1. –ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
cp .env.ollama.new .env

# 2. –ó–∞–ø—É—Å—Ç–∏—Ç—å –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã
make up

# 3. –î–æ–∂–¥–∞—Ç—å—Å—è –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏
make wait

# 4. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∑–¥–æ—Ä–æ–≤—å–µ
make health
```

## üß™ –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏

### –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞

```bash
curl http://localhost:11434/api/tags | jq '.models[] | .name'
# –î–æ–ª–∂–Ω–æ –ø–æ–∫–∞–∑–∞—Ç—å: qwen3:14b
```

### –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —á–µ—Ä–µ–∑ API

```bash
curl http://localhost:8000/model-config | jq
```

**–û–∂–∏–¥–∞–µ–º—ã–π –æ—Ç–≤–µ—Ç:**

```json
{
  "model_name": "qwen3:14b",
  "provider": "ollama",
  "context_window": 40960,
  "max_output_tokens": 2048,
  "summarization_threshold": 15000,
  "summarization_max_output": 5000,
  "effective_context_for_rag": 38912,
  "recommended_chunk_limit": 129,
  "tokens_per_second": 45
}
```

## üìä –í–∞–∂–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –æ–∫–Ω–∞

### OLLAMA_NUM_CTX vs summarization_threshold

**–î–≤–∞ —Ä–∞–∑–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–∞:**

1. **OLLAMA_NUM_CTX** = 40960 (–≤ .env –∏ docker-compose.yml)
   - –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –æ–∫–Ω–∞ –º–æ–¥–µ–ª–∏ Ollama
   - –ê–Ω–∞–ª–æ–≥ `VLLM_MAX_MODEL_LEN` –¥–ª—è vLLM
   - –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å–∫–æ–ª—å–∫–æ —Ç–æ–∫–µ–Ω–æ–≤ –º–æ–∂–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –º–æ–¥–µ–ª—å –∑–∞ –æ–¥–∏–Ω –≤—ã–∑–æ–≤
   - –î–ª—è qwen3:14b = 40960 —Ç–æ–∫–µ–Ω–æ–≤

2. **summarization_threshold** = 15000 (–≤ config/llm_models.json)
   - –ü–æ—Ä–æ–≥ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ –≤ RAG
   - –ü—Ä–∏ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–∏ —ç—Ç–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –≤–∫–ª—é—á–∞–µ—Ç—Å—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
   - –î–ª—è qwen3:14b = 15000 —Ç–æ–∫–µ–Ω–æ–≤ (~37% –æ—Ç context_window)

**–ü–æ—á–µ–º—É threshold –º–µ–Ω—å—à–µ —á–µ–º num_ctx?**

```
context_window (40960) = num_ctx
‚îú‚îÄ system_prompt (~500 tokens)
‚îú‚îÄ max_output_tokens (2048)
‚îú‚îÄ RAG context (–¥–æ ~38000 —Ç–æ–∫–µ–Ω–æ–≤)
‚îî‚îÄ safety margin

summarization_threshold (15000) = ~37% –æ—Ç effective context
```

### –ö–æ–≥–¥–∞ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è?

**–í endpoint `/ask`:**

1. –ü–æ–∏—Å–∫ –Ω–∞—Ö–æ–¥–∏—Ç N –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (chunks)
2. –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞—é—Ç—Å—è —Ç–æ–∫–µ–Ω—ã –≤ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —á–∞–Ω–∫–∞—Ö
3. **–ï–°–õ–ò** `context_tokens > 15000`:
   - ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤–∫–ª—é—á–∞–µ—Ç—Å—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è
   - –ß–∞–Ω–∫–∏ —Å—É–º–º–∞—Ä–∏–∑–∏—Ä—É—é—Ç—Å—è –¥–æ ~5000 —Ç–æ–∫–µ–Ω–æ–≤
   - Summary –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è –≤ LLM –≤–º–µ—Å—Ç–æ –≤—Å–µ—Ö —á–∞–Ω–∫–æ–≤
4. **–ò–ù–ê–ß–ï** (< 15000 —Ç–æ–∫–µ–Ω–æ–≤):
   - –û–±—ã—á–Ω—ã–π RAG (—á–∞–Ω–∫–∏ –ø–µ—Ä–µ–¥–∞—é—Ç—Å—è –∫–∞–∫ –µ—Å—Ç—å)

### –ü—Ä–∏–º–µ—Ä

```bash
# –ó–∞–ø—Ä–æ—Å —Å –±–æ–ª—å—à–∏–º top_k (–º–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)
curl -X POST http://localhost:8000/ask \
  -H "Content-Type: application/json" \
  -d '{
    "q": "–†–∞—Å—Å–∫–∞–∂–∏ –ø—Ä–æ –≤—Å–µ –ø—Ä–æ–µ–∫—Ç—ã",
    "space_id": "space_demo",
    "top_k": 50
  }' | jq

# Response –±—É–¥–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å:
{
  "answer": "...",
  "summarized": true,        # –ë—ã–ª–∞ –ª–∏ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è
  "context_tokens": 18500,   # –ò—Å—Ö–æ–¥–Ω—ã–π —Ä–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
  "model": "qwen3:14b"
}
```

## üéØ –ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –∫ –æ—Ç–ª–∞–¥–∫–µ 6 –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤

–° —ç—Ç–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π –º–æ–∂–Ω–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –≤—Å–µ 6 –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏:

1. ‚úÖ **–ü–∞—Ç—Ç–µ—Ä–Ω 1**: –ü—Ä—è–º–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è (`/summarize`)
2. ‚úÖ **–ü–∞—Ç—Ç–µ—Ä–Ω 2**: Smart Context Compression (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤ `/ask` –ø—Ä–∏ > 15K —Ç–æ–∫–µ–Ω–æ–≤)
3. ‚úÖ **–ü–∞—Ç—Ç–µ—Ä–Ω 3**: –†–µ–∂–∏–º—ã —Ä–∞–±–æ—Ç—ã (`/ask?mode=auto|normal|summarize|detailed`)
4. ‚úÖ **–ü–∞—Ç—Ç–µ—Ä–Ω 4**: Pre-computed summaries (–∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ Qdrant)
5. ‚úÖ **–ü–∞—Ç—Ç–µ—Ä–Ω 5**: –ü–æ—Ç–æ–∫–æ–≤–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è (`/summarize-stream`)
6. ‚úÖ **–ü–∞—Ç—Ç–µ—Ä–Ω 6**: –°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è —Ç—Ä–µ–¥–æ–≤ (`/thread/summarize`)

---

**–°–ª–µ–¥—É—é—â–∏–π —à–∞–≥:** –ó–∞–ø—É—Å—Ç–∏—Ç—å –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã –∏ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∂–¥—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω! üöÄ

